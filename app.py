import os
import streamlit as st
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

load_dotenv()

# -----------------------------
# A/B å°‚é–€å®¶ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®šç¾©
# -----------------------------
EXPERT_SYSTEM_PROMPTS = {
    "A": (
        "You are Expert A. "
        "You answer as a friendly travel guide specializing in Japan and Okinawa. "
        "Give practical and warm recommendations."
    ),
    "B": (
        "You are Expert B. "
        "You answer as a professional IT support engineer. "
        "Explain step-by-step in simple Japanese with clear solutions."
    ),
}


# -----------------------------
# å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ + ãƒ©ã‚¸ã‚ªé¸æŠå€¤ â†’ LLMå›ç­”
# -----------------------------
def ask_llm(input_text: str, expert_choice: str) -> str:

    system_prompt = EXPERT_SYSTEM_PROMPTS[expert_choice]

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=input_text),
    ]

    result = llm(messages)
    return result.content


# -----------------------------
# Streamlit UI
# -----------------------------
st.set_page_config(page_title="A/Bå°‚é–€å®¶LLMãƒ‡ãƒ¢", page_icon="ğŸ§ ")

st.title("ğŸ§  A/B å°‚é–€å®¶åˆ‡æ›¿ LLM ãƒ‡ãƒ¢")

st.write(
"""
ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€**LLMã®æŒ¯ã‚‹èˆã„ã‚’ A / B ã®2ç¨®é¡ã§åˆ‡ã‚Šæ›¿ãˆ**ã§ãã¾ã™ã€‚

### å°‚é–€å®¶è¨­å®š
- **A** : æ—¥æœ¬ãƒ»æ²–ç¸„ã«è©³ã—ã„æ—…è¡Œã‚¬ã‚¤ãƒ‰  
- **B** : ITã‚µãƒãƒ¼ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢  

### ä½¿ã„æ–¹
1. A ã¾ãŸã¯ B ã‚’é¸æŠ  
2. è³ªå•æ–‡ã‚’å…¥åŠ›  
3. é€ä¿¡ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™  
"""
)

expert_choice = st.radio(
    "å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã¦ãã ã•ã„",
    options=["A", "B"],
    horizontal=True
)

input_text = st.text_area(
    "å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ",
    value="æ—¥æœ¬ã®é¦–éƒ½ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚",
    height=120
)

send = st.button("é€ä¿¡", type="primary")

if send:
    if not input_text.strip():
        st.warning("å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("LLMãŒå›ç­”ä¸­..."):
            answer = ask_llm(input_text, expert_choice)

        st.subheader("å›ç­”")
        st.write(answer)

st.divider()
st.caption("â€» .env ã« OPENAI_API_KEY ã‚’è¨­å®šã—ã¦ã‹ã‚‰ streamlit run app.py ã§èµ·å‹•ã—ã¦ãã ã•ã„")